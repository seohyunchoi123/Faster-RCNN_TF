{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image, ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CSH\\Desktop\\투빅스 프로젝트 2/train/\n",
      "[]\n",
      "['000000000139.jpg', '000000000285.jpg', '000000000632.jpg', '000000000724.jpg', '000000000776.jpg', '000000000785.jpg', '000000000802.jpg', '000000000872.jpg', '000000000885.jpg', '000000001000.jpg']\n"
     ]
    }
   ],
   "source": [
    "os.getcwd() \n",
    "\n",
    "image_dir = 'C:\\\\Users\\\\CSH\\\\Desktop\\\\투빅스 프로젝트 2/train/'\n",
    "\n",
    "for path, dir, files in os.walk(image_dir):\n",
    "    print(path)\n",
    "    print(dir)\n",
    "    print(files) # 이렇게다 파일들로 들어가서 그안의 목록들까지 보는구나 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = []\n",
    "resizing = (32, 32)\n",
    "\n",
    "for path, dir, files in os.walk(image_dir):\n",
    "    for file in files:\n",
    "        image_dir = path + '/' + file \n",
    "        img = Image.open(image_dir)\n",
    "        img = img.resize(resizing)\n",
    "        if not img.format == \"RGB\": # 이미지의 포맷이 RGB가 아닐 경우, RGB로 convert 시킴\n",
    "            img = img.convert(\"RGB\")\n",
    "        train_x.append(np.array(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = image.reshape([1,32,32,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d5d9e6c748>"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imshow(image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d5d9e6a160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tg_bbox =[0.0, 13.0, 7.0, 7.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.placeholder(dtype=tf.float32, shape=[1,32,32,3]) # 이미지 데이터의 경우 shape은 [number, height, width, channels] 순이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"First_Layer\") as scope: \n",
    "    w1 = tf.Variable(tf.random_normal(shape=[3,3,3,32], stddev=0.01), name = \"W1\") # shape !!!!!!!!!!\n",
    "    L1 = tf.nn.conv2d(input= x_image, filter= w1, strides=[1,1,1,1], padding='SAME', name=\"L1\")\n",
    "    L1 = tf.nn.relu(L1)\n",
    "    L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1],  strides= [1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Second_Layer\") as scope:  \n",
    "    w2 = tf.Variable(tf.random_normal(shape=[3,3,32,64], stddev=0.01))\n",
    "    L2 = tf.nn.conv2d(input= L1, filter= w2, strides=[1,1,1,1], padding='SAME') \n",
    "    L2 = tf.nn.relu(L2)\n",
    "    L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1],  strides= [1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Second_Layer/MaxPool:0' shape=(1, 8, 8, 64) dtype=float32>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "feature_map = sess.run(L2, feed_dict={x_image: image})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 64)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_map.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window = tf.get_variable(shape=[3,3,64,64], name='window')\n",
    "intermediate_layer = tf.nn.conv2d(input=L2, filter = window, strides=[1,1,1,1], padding='VALID')\n",
    "intermediate_layer = tf.nn.sigmoid(intermediate_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Sigmoid:0' shape=(1, 6, 6, 64) dtype=float32>"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_1 = tf.get_variable(shape=[1,1,64,6], name='filter_1') # cls 2 + reg 4 = 6 (the number of filters)\n",
    "output = tf.nn.conv2d(input=intermediate_layer, filter=filter_1, strides=[1,1,1,1], padding='VALID')\n",
    "#output = tf.nn.sigmoid(output) # 렐루 하는거 맞니 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Conv2D_1:0' shape=(1, 6, 6, 6) dtype=float32>"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_ratio= image.shape[1]/feature_map.shape[1]\n",
    "width= conv_ratio *3 # 윈도우에 매칭되는 이미지상 크기를 구하는과정임. 윈도우 가로세로 길이가 3이기에 3을 곱해줌 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anchor_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_width = feature_map.shape[1]-2\n",
    "anchor_list = [] # anchor_list를 어떻게 tf graph 안에 넣지 ???>...... 저 밑에 과정들도 언제다넣냐 ..//\n",
    "for i in range(output_width):\n",
    "    for j in range(output_width):\n",
    "        anchor_list.append([i*conv_ratio, j*conv_ratio, width, width])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_iou(tf,anchor):\n",
    "    if tf[0]<anchor[0]: # tf가 x값이 더 작을때; tf가 더 왼쪽에 있을떄 (매트릭스기준)\n",
    "        intersection_width = tf[0]+tf[2]-anchor[0]\n",
    "    elif tf[0]>anchor[0]:\n",
    "        intersection_width = anchor[0]+anchor[2]-tf[0]\n",
    "    else:\n",
    "        intersection_width=tf[2]\n",
    "    if intersection_width<=0:\n",
    "        intersection_width=0\n",
    "    \n",
    "    if tf[1]>anchor[1]:#  tf가 y값이 더 클때; tf가 더 밑에 있을때 (매트릭스기준)\n",
    "        intersection_height = anchor[1]+anchor[3] -tf[1]\n",
    "    elif tf[1]<anchor[1]:\n",
    "        intersection_height = tf[1]+tf[3] -anchor[1]\n",
    "    else:\n",
    "        intersection_height=tf[3]\n",
    "    if intersection_height<=0:\n",
    "        intersection_height=0\n",
    "    intersection = intersection_width*intersection_height\n",
    "    union = tf[2]*tf[3] + anchor[2]*anchor[3]-intersection\n",
    "    return(intersection/union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_iou(anchor_list[0],anchor_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 8.0, 12.0, 12.0], [0.0, 12.0, 12.0, 12.0]]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_anchor=[]\n",
    "for anchor in anchor_list:\n",
    "    if get_iou(anchor,tg_bbox)>=0.7:\n",
    "        pos_anchor.append(anchor)\n",
    "pos_anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def position_on_feature_map(list_1): # cnn의 feature_map에서 3x3을 한번 또 거친 매트릭스상의 위치를 구하는 과정이다. \n",
    "    result=[]\n",
    "    for t in list_1:\n",
    "        result.append([t[0]/conv_ratio, t[1]/conv_ratio])\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 2.0], [0.0, 3.0]]"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position_on_feature_map(pos_anchor) # output을 텐서에서 넘파이로 꺼내온다음 로스를 구해야할듯 ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_11:0' shape=(1,) dtype=float32>"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=tf.zeros([1], dtype=tf.float32)\n",
    "for locs in position_on_feature_map(pos_anchor):\n",
    "    a = tf.cast(locs[0], tf.int32)\n",
    "    b = tf.cast(locs[1], tf.int32)\n",
    "    pos_prob = tf.cast(output[0][a][b][0], tf.float32)\n",
    "    neg_prob = tf.cast(output[0][a][b][1], tf.float32)\n",
    "    cross_entr = tf.exp(pos_prob) / (tf.exp(pos_prob)+tf.exp(neg_prob))\n",
    "    t += cross_entr\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_cls = -tf.log(t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Conv2D_1:0' shape=(1, 6, 6, 6) dtype=float32>"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def smoothing (x): # 이거 텐서안으로 어떻게 넣어 ????????????\n",
    "    t=[]\n",
    "    for i in range(x.shape.as_list()[0]):\n",
    "        if tf.abs(x[i])<1:\n",
    "            t.append(0.5*x[i]**2)\n",
    "        else:\n",
    "            t.append(tf.abs(x[i])-0.5)\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def smoothing (x): # 이거 텐서안으로 어떻게 넣어 ????????????\n",
    "    t=[]\n",
    "    for i in range(x.shape.as_list()[0]):\n",
    "        t.append(tf.cond(tf.abs(x[i])<1, lambda : 0.5*x[i]**2, lambda : tf.abs(x[i])-0.5))\n",
    "       x =  tf.scatter_update(x, [i], [tmp]) \n",
    "    return(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "smoothing(output[0][0][2][2:] - tf_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_bbox = tf.placeholder(dtype=tf.float32, shape=[4])\n",
    "\n",
    "t1 =tf.zeros([1], dtype=tf.float32)\n",
    "for locs in position_on_feature_map(pos_anchor):\n",
    "    a = tf.cast(locs[0], tf.int32)\n",
    "    b = tf.cast(locs[1], tf.int32)\n",
    "    t1 += tf.cast((output[0][a][b][2:] - tf_bbox)**2, tf.float32) # reg loss 함수 제대로 바꿔봐야함 ! ! \n",
    "loss_reg = tf.reduce_sum(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.add(loss_reg, loss_cls)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "training= optimizer.minimize(loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48951396 -1.7347106  -0.43495536  1.382464  ]\n",
      "[-0.44212168 -1.7506497  -0.4472074   1.4205359 ]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for locs in position_on_feature_map(pos_anchor):\n",
    "    a = tf.cast(locs[0], tf.int32)\n",
    "    b = tf.cast(locs[1], tf.int32)\n",
    "    print(sess.run(output[0][a][b][2:] , feed_dict={x_image:image, tf_bbox: tg_bbox}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.510825]\n",
      "[-0.6747666]\n",
      "[-0.6842097]\n",
      "[-0.68725073]\n",
      "[-0.68874925]\n",
      "[-0.6896411]\n",
      "[-0.6902325]\n",
      "[-0.6906533]\n",
      "[-0.690968]\n",
      "[-0.6912122]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    sess.run(training, feed_dict={x_image:image, tf_bbox:tg_bbox})\n",
    "    if i%100 ==0:\n",
    "        print(sess.run(loss, feed_dict={x_image:image, tf_bbox: tg_bbox}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability for Pos : 0.9982598\n",
      "Probability for Neg : 0.0017402091\n",
      "Coordinates of Bbox : [1.4901161e-08 1.3000000e+01 7.0000000e+00 7.0000000e+00] \n",
      "\n",
      "Probability for Pos : 0.9982598\n",
      "Probability for Neg : 0.0017402091\n",
      "Coordinates of Bbox : [1.4901161e-08 1.3000000e+01 7.0000000e+00 7.0000000e+00] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 회귀 잘 됏는지 확인 \n",
    "for locs in position_on_feature_map(pos_anchor):\n",
    "    a = tf.cast(locs[0], tf.int32)\n",
    "    b = tf.cast(locs[1], tf.int32)\n",
    "    print('Probability for Pos :', sess.run(tf.exp(pos_prob) / (tf.exp(pos_prob)+tf.exp(neg_prob)) , feed_dict={x_image:image, tf_bbox: tg_bbox})) \n",
    "    print('Probability for Neg :',sess.run(tf.exp(neg_prob) / (tf.exp(pos_prob)+tf.exp(neg_prob)) , feed_dict={x_image:image, tf_bbox: tg_bbox})) \n",
    "    print('Coordinates of Bbox :',sess.run(output[0][a][b][2:] , feed_dict={x_image:image, tf_bbox: tg_bbox}), '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. 13.  7.  7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(tf_bbox, feed_dict={x_image:image, tf_bbox: tg_bbox})) # 이 값이 나와야하는데 .. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 180521\n",
    "# 1. loss function 바꾸기 // 2. cnn 모델가져오기  // 3. smoothing 제대로 하기 ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이후에 fast r-cnn이랑 연결되려면 proposal받는 애의 feature_map상 위치롤 알아야함 !! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-trained model 어떻게불러오는거야 공부해보자 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.slim.nets import vgg\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vgg_16.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Tensor name \"window\" not found in checkpoint files vgg_16.ckpt\n\t [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_5', defined at:\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-97-d9ff9f5db21c>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1139, in __init__\n    self.build()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 640, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Tensor name \"window\" not found in checkpoint files vgg_16.ckpt\n\t [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Tensor name \"window\" not found in checkpoint files vgg_16.ckpt\n\t [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-d9ff9f5db21c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vgg_16.ckpt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1546\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Restoring parameters from %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[1;32m-> 1548\u001b[1;33m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[0;32m   1549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Tensor name \"window\" not found in checkpoint files vgg_16.ckpt\n\t [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]\n\nCaused by op 'save/RestoreV2_5', defined at:\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-97-d9ff9f5db21c>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1139, in __init__\n    self.build()\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1170, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 407, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 247, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 640, in restore_v2\n    dtypes=dtypes, name=name)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\CSH\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nNotFoundError (see above for traceback): Tensor name \"window\" not found in checkpoint files vgg_16.ckpt\n\t [[Node: save/RestoreV2_5 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_save/Const_0_0, save/RestoreV2_5/tensor_names, save/RestoreV2_5/shape_and_slices)]]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "sess=tf.Session()\n",
    "saver.restore(sess, 'vgg_16.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restore = slim.assign_from_checkpoint_fn(\n",
    "               'vgg_16.ckpt',\n",
    "               slim.get_model_variables(\"vgg_16\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
